{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCU6T8DpP_nM",
        "outputId": "dcd9de86-ac5b-4558-ccd2-1b2b127f9f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc2YEU3w-F9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549b2339-7f3f-4d63-e413-d7b4af274151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 24 16:15:50 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4NRcBokpq85",
        "outputId": "4ab90b8d-ca44-4424-884e-fe6ba7ad93ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi8yJ-H_JmWQ",
        "outputId": "d6a038ff-08a4-4731-ed05-c9ea2bd64c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-b9l7yequ\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-b9l7yequ\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10742 sha256=fdb30b442a03a2b978d94f242f4f3839c3b517111d4c5bcc31496f40b5aacbba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zpgbkc0b/wheels/ef/1d/c6/f7e47f1aa1bc9d05c4120d94f90a79cf28603ef343b0dd43ff\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQXJdIMWJsXh",
        "outputId": "a9c6f25b-3b2a-4777-e835-4a500aff7f7b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpreh7t1et\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile concurrent.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define N 1\n",
        "const float alertThreshold = 30.0;  // Alert threshold in m\n",
        "const float brakingThreshold = 15.0; // Braking threshold in m\n",
        "__global__ void receiveData(float *data) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    data[idx]--;\n",
        "    printf(\"Distance: %f m\\n\", data[idx]);\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void monitorDistance(float *data) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (data[idx] > alertThreshold) {\n",
        "        printf(\"Safe\\n\");\n",
        "    } else if ((data[idx] > brakingThreshold) & (data[idx] <= alertThreshold)){\n",
        "      printf(\"Obstacle detected with distance: %f m\\n\", data[idx]);\n",
        "    } else{\n",
        "      printf(\"Warning: Obstacle close with distance: %f m\\n\", data[idx]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *d_data1; //*d_data2;\n",
        "    float *h_data = new float[N];\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_data[i] = 40;\n",
        "    }\n",
        "\n",
        "    cudaMalloc(&d_data1, N * sizeof(float));\n",
        "    //cudaMalloc(&d_data2, N * sizeof(float));\n",
        "\n",
        "    cudaStream_t stream1, stream2;\n",
        "    cudaStreamCreate(&stream1);\n",
        "    cudaStreamCreate(&stream2);\n",
        "\n",
        "    cudaMemcpyAsync(d_data1, h_data, N * sizeof(float), cudaMemcpyHostToDevice, stream1);\n",
        "    //cudaMemcpyAsync(d_data2, h_data, N * sizeof(float), cudaMemcpyHostToDevice, stream2);\n",
        "\n",
        "    int threadsPerBlock = 1;\n",
        "    int blocksPerGrid = 1;\n",
        "    for(int i=0; i<40; i++){\n",
        "      receiveData<<<blocksPerGrid, threadsPerBlock, 0, stream1>>>(d_data1);\n",
        "      monitorDistance<<<blocksPerGrid, threadsPerBlock, 0, stream2>>>(d_data1);\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "    cudaMemcpyAsync(h_data, d_data1, N * sizeof(float), cudaMemcpyDeviceToHost, stream1);\n",
        "    //cudaMemcpyAsync(h_data, d_data2, N * sizeof(float), cudaMemcpyDeviceToHost, stream2);\n",
        "\n",
        "    cudaStreamSynchronize(stream1);\n",
        "    cudaStreamSynchronize(stream2);\n",
        "\n",
        "\n",
        "\n",
        "    cudaFree(d_data1);\n",
        "    //cudaFree(d_data2);\n",
        "    cudaStreamDestroy(stream1);\n",
        "    cudaStreamDestroy(stream2);\n",
        "    delete[] h_data;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ThwzoMr0BJH",
        "outputId": "9e375696-26f9-47c9-f6c0-c6c55e49d9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting concurrent.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile concurrent.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define N 2  // Number of threads/processes\n",
        "#define MATRIX_SIZE N * N\n",
        "const float alertThreshold = 30.0;  // Alert threshold in m\n",
        "const float brakingThreshold = 15.0; // Braking threshold in m\n",
        "__global__ void receiveData(float *data, int* clockMatrix, int numProcesses) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    data[idx]--;\n",
        "    printf(\"Distance: %f m\\n\", data[idx]);\n",
        "    clockMatrix[idx * numProcesses + idx]++;  // Internal event\n",
        "    printf(\"Kernel1: Process %d executed an internal event. Updated clock:\\n\", idx);\n",
        "    for (int i = 0; i < numProcesses; ++i) {\n",
        "        printf(\"%d \", clockMatrix[idx * numProcesses + i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void monitorDistance(float *data, int* clockMatrix, int numProcesses) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int idxMatrix = 1;\n",
        "    if (data[idx] > alertThreshold) {\n",
        "        printf(\"Safe\\n\");\n",
        "    } else if ((data[idx] > brakingThreshold) & (data[idx] <= alertThreshold)){\n",
        "      printf(\"Obstacle detected with distance: %f m\\n\", data[idx]);\n",
        "    } else{\n",
        "      printf(\"Warning: Obstacle close with distance: %f m\\n\", data[idx]);\n",
        "    }\n",
        "    clockMatrix[idxMatrix * numProcesses + idxMatrix]++;  // Internal event\n",
        "\n",
        "    // Synchronize with thread 0 (simulating receive event from thread 0)\n",
        "    for (int i = 0; i < numProcesses; ++i) {\n",
        "        clockMatrix[idxMatrix * numProcesses + i] = max(clockMatrix[idxMatrix * numProcesses + i], clockMatrix[0 * numProcesses + i]);\n",
        "    }\n",
        "    printf(\"Kernel2: Process %d executed an internal event and synchronized. Updated clock:\\n\", idxMatrix);\n",
        "    for (int i = 0; i < numProcesses; ++i) {\n",
        "        printf(\"%d \", clockMatrix[idxMatrix * numProcesses + i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *d_data1; //*d_data2;\n",
        "    float *h_data = new float[1];\n",
        "    // Allocate memory for the logical matrix clock on the host and device\n",
        "    int* h_clockMatrix = new int[MATRIX_SIZE];\n",
        "    int* d_clockMatrix;\n",
        "\n",
        "    for (int i = 0; i < 1; ++i) {\n",
        "        h_data[i] = 40;\n",
        "    }\n",
        "\n",
        "    cudaMalloc(&d_clockMatrix, MATRIX_SIZE * sizeof(int));\n",
        "    cudaMalloc(&d_data1, N * sizeof(float));\n",
        "    //cudaMalloc(&d_data2, N * sizeof(float));\n",
        "\n",
        "    // Initialize the clock matrix\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            h_clockMatrix[i * N + j] = (i == j) ? 1 : 0;  // Set diagonal to 1, rest to 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copy the matrix to the device\n",
        "    cudaMemcpy(d_clockMatrix, h_clockMatrix, MATRIX_SIZE * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaStream_t stream1, stream2;\n",
        "    cudaStreamCreate(&stream1);\n",
        "    cudaStreamCreate(&stream2);\n",
        "\n",
        "    cudaMemcpyAsync(d_data1, h_data, N * sizeof(float), cudaMemcpyHostToDevice, stream1);\n",
        "    //cudaMemcpyAsync(d_data2, h_data, N * sizeof(float), cudaMemcpyHostToDevice, stream2);\n",
        "\n",
        "    int threadsPerBlock = 1;\n",
        "    int blocksPerGrid = 1;\n",
        "    for(int i=0; i<2; i++){\n",
        "      receiveData<<<blocksPerGrid, threadsPerBlock, 0, stream1>>>(d_data1, d_clockMatrix, N);\n",
        "      cudaDeviceSynchronize();\n",
        "      monitorDistance<<<blocksPerGrid, threadsPerBlock, 0, stream2>>>(d_data1, d_clockMatrix, N);\n",
        "      cudaDeviceSynchronize();\n",
        "\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(h_clockMatrix, d_clockMatrix, MATRIX_SIZE * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpyAsync(h_data, d_data1, N * sizeof(float), cudaMemcpyDeviceToHost, stream1);\n",
        "    //cudaMemcpyAsync(h_data, d_data2, N * sizeof(float), cudaMemcpyDeviceToHost, stream2);\n",
        "\n",
        "    // Print the final clock matrix\n",
        "    std::cout << \"Final Clock Matrix on Host:\\n\";\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            std::cout << h_clockMatrix[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << \"\\n\";\n",
        "    }\n",
        "\n",
        "    cudaStreamSynchronize(stream1);\n",
        "    cudaStreamSynchronize(stream2);\n",
        "\n",
        "\n",
        "\n",
        "    cudaFree(d_data1);\n",
        "    //cudaFree(d_data2);\n",
        "    cudaStreamDestroy(stream1);\n",
        "    cudaStreamDestroy(stream2);\n",
        "    delete[] h_data;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpwKZ12ZroKX",
        "outputId": "ec4e396a-4936-4e63-8c51-917ee6e147ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting concurrent.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --default-stream per-thread ./concurrent.cu -o concurrent\n",
        "!nvprof ./concurrent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRS4GBDFmBvY",
        "outputId": "bd2bc1c0-2348-47c7-b474-03197401b501"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==8271== NVPROF is profiling process 8271, command: ./concurrent\n",
            "Distance: 39.000000 m\n",
            "Kernel1: Process 0 executed an internal event. Updated clock:\n",
            "2 0 \n",
            "Safe\n",
            "Kernel2: Process 1 executed an internal event and synchronized. Updated clock:\n",
            "2 2 \n",
            "Distance: 38.000000 m\n",
            "Kernel1: Process 0 executed an internal event. Updated clock:\n",
            "3 0 \n",
            "Safe\n",
            "Kernel2: Process 1 executed an internal event and synchronized. Updated clock:\n",
            "3 3 \n",
            "Final Clock Matrix on Host:\n",
            "3 0 \n",
            "3 3 \n",
            "==8271== Profiling application: ./concurrent\n",
            "==8271== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   49.81%  672.40us         2  336.20us  336.09us  336.31us  monitorDistance(float*, int*, int)\n",
            "                   49.74%  671.47us         2  335.73us  329.40us  342.07us  receiveData(float*, int*, int)\n",
            "                    0.31%  4.1600us         2  2.0800us  2.0800us  2.0800us  [CUDA memcpy DtoH]\n",
            "                    0.14%  1.8240us         2     912ns     672ns  1.1520us  [CUDA memcpy HtoD]\n",
            "      API calls:   94.52%  91.873ms         2  45.937ms  4.9040us  91.868ms  cudaMalloc\n",
            "                    3.67%  3.5715ms         4  892.87us  9.1110us  3.5319ms  cudaLaunchKernel\n",
            "                    1.47%  1.4307ms         4  357.67us  346.73us  378.44us  cudaDeviceSynchronize\n",
            "                    0.15%  146.53us       114  1.2850us     146ns  57.412us  cuDeviceGetAttribute\n",
            "                    0.07%  71.240us         2  35.620us  28.320us  42.920us  cudaMemcpy\n",
            "                    0.03%  30.362us         2  15.181us  13.543us  16.819us  cudaMemcpyAsync\n",
            "                    0.02%  21.910us         2  10.955us  4.0110us  17.899us  cudaStreamCreate\n",
            "                    0.01%  13.879us         2  6.9390us  2.6450us  11.234us  cudaStreamDestroy\n",
            "                    0.01%  12.681us         1  12.681us  12.681us  12.681us  cuDeviceGetName\n",
            "                    0.01%  11.007us         1  11.007us  11.007us  11.007us  cudaFree\n",
            "                    0.01%  6.7900us         2  3.3950us  1.8000us  4.9900us  cudaStreamSynchronize\n",
            "                    0.01%  5.5480us         1  5.5480us  5.5480us  5.5480us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.3880us         1  4.3880us  4.3880us  4.3880us  cuDeviceTotalMem\n",
            "                    0.00%  1.4240us         3     474ns     200ns  1.0060us  cuDeviceGetCount\n",
            "                    0.00%     797ns         2     398ns     160ns     637ns  cuDeviceGet\n",
            "                    0.00%     759ns         1     759ns     759ns     759ns  cuModuleGetLoadingMode\n",
            "                    0.00%     219ns         1     219ns     219ns     219ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./concurrent"
      ],
      "metadata": {
        "id": "eES7Xkt3GlPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Xcompiler=\"-fopenmp\" -arch=sm_75 -o DPS DPS.cu\n",
        "!OMP_NUM_THREADS=4\n",
        "!./DPS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4m7xK-Iru2W",
        "outputId": "3255d131-ce19-453b-ce8f-0934cee4bbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[KDPS.cu: No such file or directory\n",
            "compilation terminated.\n",
            "/bin/bash: line 1: ./DPS: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc concurrent_tasks.cu -o concurrent_tasks\n",
        "!./concurrent_tasks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEYJ2aUlIcsx",
        "outputId": "631b4dea-5f70-455d-ba7b-47efe2a37a83",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance is: 0\n",
            "Distance is: 1\n",
            "Distance is: 2\n",
            "Distance is: 3\n",
            "Distance is: 4\n",
            "Distance is: 5\n",
            "Distance is: 6\n",
            "Distance is: 7\n",
            "Distance is: 8\n",
            "Distance is: 9\n",
            "Distance is: 10\n",
            "Distance is: 11\n",
            "Distance is: 12\n",
            "Distance is: 13\n",
            "Distance is: 14\n",
            "Distance is: 15\n",
            "Distance is: 16\n",
            "Distance is: 17\n",
            "Distance is: 18\n",
            "Distance is: 19\n",
            "Distance is: 20\n",
            "Distance is: 21\n",
            "Distance is: 22\n",
            "Distance is: 23\n",
            "Distance is: 24\n",
            "Distance is: 25\n",
            "Distance is: 26\n",
            "Distance is: 27\n",
            "Distance is: 28\n",
            "Distance is: 29\n",
            "Distance is: 30\n",
            "Distance is: 31\n",
            "Distance is: 32\n",
            "Distance is: 33\n",
            "Distance is: 34\n",
            "Distance is: 35\n",
            "Distance is: 36\n",
            "Distance is: 37\n",
            "Distance is: 38\n",
            "Distance is: 39\n",
            "Distance is: 40\n",
            "Distance is: 41\n",
            "Distance is: 42\n",
            "Distance is: 43\n",
            "Distance is: 44\n",
            "Distance is: 45\n",
            "Distance is: 46\n",
            "Distance is: 47\n",
            "Distance is: 48\n",
            "Distance is: 49\n",
            "Distance is: 50\n",
            "Distance is: 51\n",
            "Distance is: 52\n",
            "Distance is: 53\n",
            "Distance is: 54\n",
            "Distance is: 55\n",
            "Distance is: 56\n",
            "Distance is: 57\n",
            "Distance is: 58\n",
            "Distance is: 59\n",
            "Distance is: 60\n",
            "Distance is: 61\n",
            "Distance is: 62\n",
            "Distance is: 63\n",
            "Distance is: 64\n",
            "Distance is: 65\n",
            "Distance is: 66\n",
            "Distance is: 67\n",
            "Distance is: 68\n",
            "Distance is: 69\n",
            "Distance is: 70\n",
            "Distance is: 71\n",
            "Distance is: 72\n",
            "Distance is: 73\n",
            "Distance is: 74\n",
            "Distance is: 75\n",
            "Distance is: 76\n",
            "Distance is: 77\n",
            "Distance is: 78\n",
            "Distance is: 79\n",
            "Distance is: 80\n",
            "Distance is: 81\n",
            "Distance is: 82\n",
            "Distance is: 83\n",
            "Distance is: 84\n",
            "Distance is: 85\n",
            "Distance is: 86\n",
            "Distance is: 87\n",
            "Distance is: 88\n",
            "Distance is: 89\n",
            "Distance is: 90\n",
            "Distance is: 91\n",
            "Distance is: 92\n",
            "Distance is: 93\n",
            "Distance is: 94\n",
            "Distance is: 95\n",
            "Distance is: 96\n",
            "Distance is: 97\n",
            "Distance is: 98\n",
            "Distance is: 99\n",
            "TestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTestTest"
          ]
        }
      ]
    }
  ]
}